Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to ./lego_tensorboard/nmax 14 ntensor 6 (normalized) None_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.43     |
|    ep_rew_mean     | -8.42    |
| time/              |          |
|    fps             | 31       |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 100      |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.58        |
|    ep_rew_mean          | -8.31       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 2           |
|    time_elapsed         | 6           |
|    total_timesteps      | 200         |
| train/                  |             |
|    approx_kl            | 0.021238567 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | -0.0193     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.83        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 22.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.69        |
|    ep_rew_mean          | -8.34       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 3           |
|    time_elapsed         | 9           |
|    total_timesteps      | 300         |
| train/                  |             |
|    approx_kl            | 0.023348069 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | -0.000395   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.99        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0554     |
|    value_loss           | 3.81        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 5.52        |
|    ep_rew_mean          | -8.31       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 4           |
|    time_elapsed         | 12          |
|    total_timesteps      | 400         |
| train/                  |             |
|    approx_kl            | 0.022315713 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.000541    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.552       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 2.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 6.18        |
|    ep_rew_mean          | -8.29       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 5           |
|    time_elapsed         | 15          |
|    total_timesteps      | 500         |
| train/                  |             |
|    approx_kl            | 0.027267024 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | -0.0032     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0209     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 0.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 6.92        |
|    ep_rew_mean          | -8.27       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 6           |
|    time_elapsed         | 18          |
|    total_timesteps      | 600         |
| train/                  |             |
|    approx_kl            | 0.038928494 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | -0.0015     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0754     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0585     |
|    value_loss           | 0.234       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.63        |
|    ep_rew_mean          | -8.25       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 7           |
|    time_elapsed         | 22          |
|    total_timesteps      | 700         |
| train/                  |             |
|    approx_kl            | 0.047694962 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | -0.00303    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.11       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0669     |
|    value_loss           | 0.0166      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.13        |
|    ep_rew_mean          | -8.25       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 8           |
|    time_elapsed         | 25          |
|    total_timesteps      | 800         |
| train/                  |             |
|    approx_kl            | 0.042977855 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | -0.00065    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0975     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0528     |
|    value_loss           | 0.0526      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.85        |
|    ep_rew_mean          | -8.25       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 9           |
|    time_elapsed         | 28          |
|    total_timesteps      | 900         |
| train/                  |             |
|    approx_kl            | 0.027418135 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.000867    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0332      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0327     |
|    value_loss           | 0.0739      |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 9.74      |
|    ep_rew_mean          | -8.23     |
| time/                   |           |
|    fps                  | 31        |
|    iterations           | 10        |
|    time_elapsed         | 31        |
|    total_timesteps      | 1000      |
| train/                  |           |
|    approx_kl            | 0.0490065 |
|    clip_fraction        | 0.287     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.06     |
|    explained_variance   | -0.00511  |
|    learning_rate        | 0.0003    |
|    loss                 | -0.111    |
|    n_updates            | 90        |
|    policy_gradient_loss | -0.0655   |
|    value_loss           | 0.0233    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.6        |
|    ep_rew_mean          | -8.21       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 11          |
|    time_elapsed         | 34          |
|    total_timesteps      | 1100        |
| train/                  |             |
|    approx_kl            | 0.054405924 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.00418     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.11       |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0689     |
|    value_loss           | 0.012       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 11.3       |
|    ep_rew_mean          | -8.13      |
| time/                   |            |
|    fps                  | 31         |
|    iterations           | 12         |
|    time_elapsed         | 37         |
|    total_timesteps      | 1200       |
| train/                  |            |
|    approx_kl            | 0.03712991 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.13      |
|    explained_variance   | 0.00775    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.123     |
|    n_updates            | 110        |
|    policy_gradient_loss | -0.0586    |
|    value_loss           | 0.0183     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 12          |
|    ep_rew_mean          | -8.1        |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 13          |
|    time_elapsed         | 41          |
|    total_timesteps      | 1300        |
| train/                  |             |
|    approx_kl            | 0.029469546 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | 0.000938    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0592     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0462     |
|    value_loss           | 0.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 13          |
|    ep_rew_mean          | -8.09       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 14          |
|    time_elapsed         | 44          |
|    total_timesteps      | 1400        |
| train/                  |             |
|    approx_kl            | 0.035575703 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.00243     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0977     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.056      |
|    value_loss           | 0.0143      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 13.4        |
|    ep_rew_mean          | -8.06       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 15          |
|    time_elapsed         | 47          |
|    total_timesteps      | 1500        |
| train/                  |             |
|    approx_kl            | 0.031994186 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.000165   |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0689     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0537     |
|    value_loss           | 0.0145      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.1        |
|    ep_rew_mean          | -8.08       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 16          |
|    time_elapsed         | 50          |
|    total_timesteps      | 1600        |
| train/                  |             |
|    approx_kl            | 0.014701981 |
|    clip_fraction        | 0.0773      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.000408    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0794     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0209     |
|    value_loss           | 0.0885      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.3        |
|    ep_rew_mean          | -8.02       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 17          |
|    time_elapsed         | 54          |
|    total_timesteps      | 1700        |
| train/                  |             |
|    approx_kl            | 0.028083585 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.00139     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0502     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0402     |
|    value_loss           | 0.0668      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 14.2       |
|    ep_rew_mean          | -8.01      |
| time/                   |            |
|    fps                  | 31         |
|    iterations           | 18         |
|    time_elapsed         | 57         |
|    total_timesteps      | 1800       |
| train/                  |            |
|    approx_kl            | 0.01725339 |
|    clip_fraction        | 0.0896     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.77      |
|    explained_variance   | 0.000349   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0136     |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.0285    |
|    value_loss           | 0.0903     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 14.2        |
|    ep_rew_mean          | -8.02       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 19          |
|    time_elapsed         | 60          |
|    total_timesteps      | 1900        |
| train/                  |             |
|    approx_kl            | 0.021288287 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.00353     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0925     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0454     |
|    value_loss           | 0.00999     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 13.3        |
|    ep_rew_mean          | -7.98       |
| time/                   |             |
|    fps                  | 31          |
|    iterations           | 20          |
|    time_elapsed         | 64          |
|    total_timesteps      | 2000        |
| train/                  |             |
|    approx_kl            | 0.021652892 |
|    clip_fraction        | 0.0999      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.00233     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0295      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0345     |
|    value_loss           | 0.271       |
-----------------------------------------
64.94719457626343
Wrote profile results to MPPO_script_for_edit_1.py.lprof
Timer unit: 1e-06 s

Total time: 30.9361 s
File: MPPO_script_for_edit_1.py
Function: is_valid at line 20

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    20                                           #@profile
    21                                           def is_valid(state, action, env, num_max_actions, max_tensors, num_min_actions=0):
    22   1274000     547070.5      0.4      1.8      if state[-1] == 1:
    23                                                   return False
    24   1274000     356244.5      0.3      1.2      num_tensor_actions = env.num_tensor_types * env.max_tensors
    25   1274000    7092863.4      5.6     22.9      num_contractions = np.sum(state[num_tensor_actions:])
    26                                               # make sure not too many actions are taken
    27   1274000     326673.7      0.3      1.1      if num_contractions >= num_max_actions:
    28                                                   if action == env.action_space.n-1:
    29                                                       return True
    30                                                   else:
    31                                                       return False
    32   1274000     172593.7      0.1      0.6      action_valid = True
    33   1274000    3504778.4      2.8     11.3      num_active_tensors = (state == 0).argmax(axis=0) # locates first 0 in the tensor arena
    34   1274000     187570.3      0.1      0.6      num_legs_per_tensor = 5 # this will change later based on the environmnet
    35   1274000     335373.7      0.3      1.1      num_active_legs = num_active_tensors  * num_legs_per_tensor
    36   1274000     273766.7      0.2      0.9      if action < num_tensor_actions:
    37                                                   # double check that tensor is not already selected
    38                                                   # double check that previous tensor spots are already filled
    39     12000       5679.2      0.5      0.0          tensor_idx, tensor_type = action // env.num_tensor_types, action % env.num_tensor_types
    40     12000       8027.9      0.7      0.0          if state[tensor_idx] != 0 or (tensor_idx != 0 and state[tensor_idx -1] == 0):
    41     10199       2335.8      0.2      0.0              action_valid = False
    42   1262000     384082.4      0.3      1.2      elif action < num_tensor_actions + env.num_leg_combinations:
    43                                                   # leg contractions
    44                                                   # check that there are no collisions
    45   1260000    4588226.9      3.6     14.8          (leg1, leg2), possible_conflicted_contractions = env.get_leg_indices_from_contraction_index(action - num_tensor_actions)
    46                                                   #todo for文がないように書き換え
    47   1260000    1875524.1      1.5      6.1          conflict_indices = possible_conflicted_contractions + env.max_tensors
    48   1260000    9375599.0      7.4     30.3          if np.any(state[conflict_indices] != 0):
    49    461940      88817.2      0.2      0.3              action_valid = False
    50    461940      54375.9      0.1      0.2              return action_valid     
    51                                                   # check that the legs in question are spawned by tensors
    52    798060     248794.2      0.3      0.8          if leg1 >= num_active_legs or leg2 >= num_active_legs:
    53    749671     128163.6      0.2      0.4              action_valid = False
    54    798060     401167.7      0.5      1.3          if leg1//env.tensor_size == leg2 //env.tensor_size:
    55    124662      22506.2      0.2      0.1              action_valid = False
    56                                                   # check that it doesn't leave us with too few legs
    57    798060     275200.6      0.3      0.9          num_contracted_legs = 2 * num_contractions
    58    798060     490841.6      0.6      1.6          if num_active_legs - num_contracted_legs - 2 <= env.min_legs:
    59    312885      59007.7      0.2      0.2              action_valid = False
    60                                               else:
    61                                                   # terminating
    62      2000        610.1      0.3      0.0          if num_contractions < num_min_actions:
    63                                                       action_valid = False
    64                                           
    65    812060     130229.4      0.2      0.4      return action_valid

